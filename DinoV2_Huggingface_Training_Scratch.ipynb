{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "391c7706-ab76-4596-892f-fb4e7ed3dc70",
   "metadata": {},
   "source": [
    "# Imports and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9980ff5-6cf2-41c4-9722-5fa03a492b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e96661a-3323-4e74-9c3d-c131a8a5efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e11e8e9-2ef0-4985-8d39-82618f5fee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e841a8d8-6e20-4571-b134-e310908f1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1422980-063c-45e8-a6c5-fa1935b4b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename=f\"{timestamp}.log\", encoding='utf-8', level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "fileHandler = logging.FileHandler(f\"{timestamp}.log\")\n",
    "fileHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fileHandler.setFormatter(formatter)\n",
    "consoleHandler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fileHandler)\n",
    "logger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27661c2e-8034-46c3-babb-abdd92d17439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "from flash.core.optimizers import LinearWarmupCosineAnnealingLR\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, DPTForDepthEstimation, get_scheduler, Dinov2Config, DPTConfig\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1204e5c-2e80-4741-9d78-669e0d5d176b",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762c3835-0237-4f83-8637-f4da217ce2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b9ba7b4-7dd2-4f7d-9bd6-97895377b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:47:40,682 - __main__ - INFO - using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"using device {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6b1f15-92af-4325-9281-4c22c46f6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_TYPE = \"scratch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d03ca20-f559-4006-afba-49ebff9b5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE_TYPE = 'small' # in (\"small\", \"base\", \"large\" or \"giant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e90f11-4c9f-4232-a8b6-d413e6e1ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074ae3eb-683b-4999-97f9-e8fc34c0fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_PATH = \"HF-model_small_scratch_20240113_103956_102\"\n",
    "if RESUME_PATH is not None:\n",
    "    BACKBONE_TYPE = RESUME_PATH.split('/')[-1].split('_')[1]\n",
    "    HEAD_TYPE = RESUME_PATH.split('/')[-1].split('_')[2]\n",
    "    RESUME_EPOCH = int(RESUME_PATH.split('/')[-1].split('_')[-1])\n",
    "    STATE_PATH = RESUME_PATH.split('-')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a015c6fb-61fe-4821-b28c-c9e5f624000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_NAME = f\"facebook/dinov2-{BACKBONE_TYPE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4af32055-55c0-445c-9b47-747a569ab49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"/home/jovyan/work/saved_data/data/thumbnails/test\"\n",
    "TEST_PATH = \"/home/jovyan/work/saved_data/data/thumbnails/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1706c93d-69c4-4c03-b726-640c8275e676",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500 - RESUME_EPOCH\n",
    "BATCH_SIZE = 32\n",
    "EVAL_INTERVAL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b482e2cb-71f3-412e-828b-d100f994d1fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_LR = 1e-8\n",
    "WARMUP_LR = 1e-9\n",
    "END_LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0dff5a5-ce8e-4499-ad70-24f4ab335b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BACKBONE = False\n",
    "TRAIN_NECK = True\n",
    "TRAIN_HEAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37bf60ad-6a23-48f1-80f1-59f626279db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DROP = 0\n",
    "ATTENTION_DROP = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63c15f-b8a4-457f-bc4e-80b02ad6e56d",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9dc4a0-e4c6-4e65-9f21-d6e169af4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNPZDataset(Dataset):\n",
    "    def __init__(self, path, image_processor, transform=None, image_transforms=None):\n",
    "        self.path = path\n",
    "        self.files = list(Path(path).glob('*.npz'))\n",
    "        self.image_processor = image_processor\n",
    "        self.transform = transform\n",
    "        self.image_transforms = image_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        with np.load(str(self.files[item])) as data:\n",
    "            X_numpy = data['X']\n",
    "            y_numpy = data['y']\n",
    "        X_torch = torch.from_numpy(X_numpy)\n",
    "        y_torch = torch.from_numpy(y_numpy).unsqueeze(0)\n",
    "        if self.transform is not None:\n",
    "            X_torch = self.transform(X_torch)\n",
    "            y_torch = self.transform(y_torch)\n",
    "        if self.image_transforms is not None:\n",
    "            X_torch = self.transform(X_torch)\n",
    "        return X_torch, y_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d4dc7fe-aaba-4f36-b0e0-2a5ee50432de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperSigLoss(nn.Module):\n",
    "    def __init__(self, valid_mask=True, a=10, l=0.85):\n",
    "        super(PaperSigLoss, self).__init__()\n",
    "        \n",
    "        self.valid_mask = valid_mask\n",
    "\n",
    "        self.alpha = a\n",
    "        self.lamb = l\n",
    "\n",
    "        self.eps = 0.001  # avoid grad explode\n",
    "        \n",
    "    def paperSigloss(self, input, target):\n",
    "        if self.valid_mask:\n",
    "            valid_mask = target > 0\n",
    "            input = input[valid_mask]\n",
    "            target = target[valid_mask]\n",
    "\n",
    "        delta = torch.log(target + self.eps) - torch.log(input + self.eps)\n",
    "        loss = torch.mean(delta ** 2) - self.lamb / ((torch.numel(delta)) ** 2) * (torch.sum(delta) ** 2) \n",
    "        return loss\n",
    "\n",
    "    def forward(self, depth_pred, depth_gt):\n",
    "        loss_depth = self.paperSigloss(depth_pred, depth_gt)\n",
    "        return self.alpha * loss_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7563cef-46c5-4417-b3c6-d60edc0f86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self, valid_mask=True, max_depth=None):\n",
    "        super(SigLoss, self).__init__()\n",
    "        \n",
    "        self.valid_mask = valid_mask\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        self.eps = 0.001  # avoid grad explode\n",
    "\n",
    "    def sigloss(self, input, target):\n",
    "        if self.valid_mask:\n",
    "            valid_mask = target > 0\n",
    "            if self.max_depth is not None:\n",
    "                valid_mask = torch.logical_and(target > 0, target <= self.max_depth)\n",
    "            input = input[valid_mask]\n",
    "            target = target[valid_mask]\n",
    "\n",
    "        g = torch.log(input + self.eps) - torch.log(target + self.eps)\n",
    "        Dg = torch.var(g) + 0.15 * torch.pow(torch.mean(g), 2)\n",
    "        return torch.sqrt(Dg)\n",
    "\n",
    "    def forward(self, depth_pred, depth_gt):\n",
    "        loss_depth = self.sigloss(depth_pred, depth_gt)\n",
    "        return loss_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f1ab4f-0fac-47e0-b3a0-b73c6b75cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMAE(nn.Module):\n",
    "    def __init__(self, valid_mask=True, max_depth=None):\n",
    "        super(MaskedMAE, self).__init__()\n",
    "        \n",
    "        self.valid_mask = valid_mask\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def mae(self, input, target):\n",
    "        if self.valid_mask:\n",
    "            valid_mask = target > 0\n",
    "            if self.max_depth is not None:\n",
    "                valid_mask = torch.logical_and(target > 0, target <= self.max_depth)\n",
    "            input = input[valid_mask]\n",
    "            target = target[valid_mask]\n",
    "\n",
    "        mae = torch.abs(input - target).mean()\n",
    "        return mae\n",
    "    \n",
    "    def forward(self, depth_pred, depth_gt):\n",
    "        metric_mae = self.mae(depth_pred, depth_gt)\n",
    "        return metric_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "198f7754-341c-4828-a749-53381277b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedR2Score(nn.Module):\n",
    "    def __init__(self, valid_mask=True, max_depth=None):\n",
    "        super(MaskedR2Score, self).__init__()\n",
    "\n",
    "        self.valid_mask = valid_mask\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def r2(self, input, target):\n",
    "        if self.valid_mask:\n",
    "            valid_mask = target > 0\n",
    "            if self.max_depth is not None:\n",
    "                valid_mask = torch.logical_and(target > 0, target <= self.max_depth)\n",
    "            input = input[valid_mask]\n",
    "            target = target[valid_mask]\n",
    "\n",
    "        mean_target = torch.mean(target)\n",
    "        ss_total = torch.sum((target - mean_target)**2)\n",
    "        ss_residual = torch.sum((input - target)**2)\n",
    "\n",
    "        r2 = 1 - (ss_residual / ss_total)\n",
    "        return r2\n",
    "    \n",
    "    def forward(self, depth_pred, depth_gt):\n",
    "        metric_r2 = self.r2(depth_pred, depth_gt)\n",
    "        return metric_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60180a32-d5b2-4de8-a20d-49d0e64b8ffd",
   "metadata": {},
   "source": [
    "# Initiallization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cffa742b-1f9d-4fc3-9a81-1e25265ffb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(CONFIG_NAME)\n",
    "\n",
    "backbone_config = Dinov2Config.from_pretrained(\n",
    "    CONFIG_NAME, \n",
    "    out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"], \n",
    "    reshape_hidden_states=False,\n",
    "    hidden_dropout_prob=HIDDEN_DROP,\n",
    "    attention_probs_dropout_prob=ATTENTION_DROP\n",
    ")\n",
    "config = DPTConfig(\n",
    "    backbone_config=backbone_config,\n",
    "    hidden_dropout_prob=HIDDEN_DROP,\n",
    "    attention_probs_dropout_prob=ATTENTION_DROP\n",
    ")\n",
    "\n",
    "if RESUME_PATH is None:\n",
    "    model = DPTForDepthEstimation(config=config)\n",
    "else:\n",
    "    model = DPTForDepthEstimation.from_pretrained(RESUME_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87b7f811-d922-4c50-8236-8573bc390f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5faca390-48c6-4934-a64f-57a48c99b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_transform = transforms.Compose([\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(90)#,\n",
    "    # transforms.RandomResizedCrop((IMAGE_SIZE[0], IMAGE_SIZE[1]), scale=(0.8, 1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebe3df72-018b-47bf-a325-812602d8739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_only_transforms = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaf7c9af-2223-436b-b04a-ee21017764c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomNPZDataset(path=TRAIN_PATH, image_processor=image_processor)#, transform=augmentation_transform, image_transforms=img_only_transforms)\n",
    "validation_dataset = CustomNPZDataset(path=TEST_PATH, image_processor=image_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d800fc17-c250-420f-9b89-27f93e8ed83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=8, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b0c9d4b-ad27-42d4-882e-c27a0f70af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=START_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6639c55-cc99-41eb-8457-21da3f64d188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:47:42,153 - __main__ - INFO - 55720 Total Steps\n"
     ]
    }
   ],
   "source": [
    "total_steps = EPOCHS * len(training_loader)\n",
    "logger.info(f\"{total_steps} Total Steps\")\n",
    "lr_scheduler = LinearWarmupCosineAnnealingLR(optimizer, 12000, total_steps, warmup_start_lr=WARMUP_LR, eta_min=END_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df9aee5e-26b4-4f17-990b-4262b9eb326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:47:42,160 - __main__ - INFO - Continueing at step 14280\n"
     ]
    }
   ],
   "source": [
    "last_step = RESUME_EPOCH * len(training_loader)\n",
    "logger.info(f\"Continueing at step {last_step}\")\n",
    "for _ in range(last_step):\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3284ecde-e82e-4f9a-8d4f-6f4515377e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = PaperSigLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ac56f2d-0b69-492b-a9a6-737125d25d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_fn = MaskedMAE()\n",
    "r2_fn = MaskedR2Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f615045-8e7a-4821-a526-8197a9ce0bc9",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82de64be-b0c8-47e9-b4ad-5d78b538d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data):\n",
    "    inputs, labels = data\n",
    "\n",
    "    images = [Image.fromarray(input.numpy().transpose(1, 2, 0)) for input in inputs]\n",
    "\n",
    "    inputs = image_processor(images=images, return_tensors=\"pt\")\n",
    "\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    predicted_depth = outputs['predicted_depth']\n",
    "\n",
    "    predictions = torch.nn.functional.interpolate(\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=IMAGE_SIZE,\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    labels = labels.to(DEVICE)\n",
    "    \n",
    "    loss = loss_fn(predictions, labels)\n",
    "\n",
    "    mae = mae_fn(predictions, labels)\n",
    "    r2 = r2_fn(predictions, labels)\n",
    "    \n",
    "    return loss, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27b95a49-e31f-44d5-8b17-2045f115d485",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    running_loss = 0.\n",
    "    epoch_loss = 0.\n",
    "\n",
    "    running_mae = 0.\n",
    "    running_r2 = 0.\n",
    "    epoch_mae = 0.\n",
    "    epoch_r2 = 0.\n",
    "\n",
    "    for i, data in tqdm(enumerate(training_loader), total=len(training_loader)):\n",
    "        loss, mae, r2 = run_model(data)\n",
    "\n",
    "        if loss.isnan().all():\n",
    "            logger.error(\"Exploding Gradeints!\")\n",
    "            raise Exception('Exploding Gradients!')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1e-3)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        running_mae += mae.item()\n",
    "        running_r2 += r2.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(training_loader)\n",
    "\n",
    "    epoch_mae = running_mae / len(training_loader)\n",
    "    epoch_r2 = running_r2 / len(training_loader)\n",
    "    \n",
    "    return epoch_loss, epoch_mae, epoch_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7f7ee08-66ac-428f-b84a-94200188e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler.get_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b97d5f-9309-4048-a5fc-8f296fed2bd8",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "592acf19-704b-4185-a4ea-f6069614fbb4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:47:42,245 - __main__ - INFO - EPOCH 103:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fbce71b3ab4f6398b4757bb3f0a048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:49:10,839 - __main__ - INFO - LOSS Train 4.996352878638676\n",
      "2024-01-15 09:49:10,840 - __main__ - INFO - MAE Train 2.5307401376111165\n",
      "2024-01-15 09:49:10,841 - __main__ - INFO - R2 Train 0.8337895806346621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3c6a1400b34aebaaacabc46c33286d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:50:08,890 - __main__ - INFO - LOSS valid 18.485225677490234\n",
      "2024-01-15 09:50:08,893 - __main__ - INFO - MAE valid 4.455069541931152\n",
      "2024-01-15 09:50:08,895 - __main__ - INFO - R2 valid 0.4657798409461975\n",
      "2024-01-15 09:50:09,221 - __main__ - INFO - EPOCH 104:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e8d8cce1254dd397a85a78f8fcee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:51:37,220 - __main__ - INFO - LOSS Train 4.891311999729702\n",
      "2024-01-15 09:51:37,221 - __main__ - INFO - MAE Train 2.4929042220115663\n",
      "2024-01-15 09:51:37,222 - __main__ - INFO - R2 Train 0.836650635940688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce27f802ceaa4a73936902d40e203db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:52:35,478 - __main__ - INFO - LOSS valid 18.459365844726562\n",
      "2024-01-15 09:52:35,480 - __main__ - INFO - MAE valid 4.470583438873291\n",
      "2024-01-15 09:52:35,483 - __main__ - INFO - R2 valid 0.4617373049259186\n",
      "2024-01-15 09:52:35,806 - __main__ - INFO - EPOCH 105:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5ae77877ac44f29f09ed836a93a625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:53:38,654 - __main__ - ERROR - Exploding Gradeints!\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Exploding Gradients!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     17\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m TRAIN_HEAD\n\u001b[0;32m---> 19\u001b[0m avg_loss, avg_mae, avg_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOSS Train \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(avg_loss))\n\u001b[1;32m     23\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE Train \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(avg_mae))\n",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m     14\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExploding Gradeints!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExploding Gradients!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mException\u001b[0m: Exploding Gradients!"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(f\"runs/dinov2_{BACKBONE_TYPE}_dpt_{HEAD_TYPE}_{timestamp}\")\n",
    "\n",
    "epoch_number = 1 + RESUME_EPOCH\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(RESUME_EPOCH, EPOCHS+RESUME_EPOCH):\n",
    "    logger.info('EPOCH {}:'.format(epoch_number))\n",
    "\n",
    "    model.train(True)\n",
    "    \n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = TRAIN_BACKBONE\n",
    "    for param in model.neck.parameters():\n",
    "        param.requires_grad = TRAIN_NECK\n",
    "    for param in model.head.parameters():\n",
    "        param.requires_grad = TRAIN_HEAD\n",
    "        \n",
    "    avg_loss, avg_mae, avg_r2 = train_one_epoch()\n",
    "\n",
    "    logger.info('LOSS Train {}'.format(avg_loss))\n",
    "\n",
    "    logger.info('MAE Train {}'.format(avg_mae))\n",
    "    logger.info('R2 Train {}'.format(avg_r2))\n",
    "\n",
    "    writer.add_scalars('Training Loss',\n",
    "                        { 'Training' : avg_loss },\n",
    "                        epoch_number)\n",
    "    writer.add_scalars('Training MAE',\n",
    "                    { 'Training' : avg_mae },\n",
    "                    epoch_number)\n",
    "    writer.add_scalars('Training R2',\n",
    "                    { 'Training' : avg_r2 },\n",
    "                    epoch_number)\n",
    "\n",
    "    if epoch_number % EVAL_INTERVAL == 0:\n",
    "        running_vloss = 0.0\n",
    "\n",
    "        running_vmae = 0.0\n",
    "        running_vr2 = 0.0\n",
    "    \n",
    "        model.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, vdata in tqdm(enumerate(validation_loader), total=len(validation_loader)):\n",
    "                vloss, vmae, vr2 = run_model(vdata)\n",
    "                running_vloss += vloss\n",
    "                running_vmae += vmae\n",
    "                running_vr2 += vr2\n",
    "    \n",
    "        avg_vloss = running_vloss / len(validation_loader)\n",
    "        logger.info('LOSS valid {}'.format(avg_vloss))\n",
    "    \n",
    "        avg_vmae = running_vmae / len(validation_loader)\n",
    "        logger.info('MAE valid {}'.format(avg_vmae))\n",
    "        avg_vr2 = running_vr2 / len(validation_loader)\n",
    "        logger.info('R2 valid {}'.format(avg_vr2))\n",
    "    \n",
    "        writer.add_scalars('Validation Loss',\n",
    "                        { 'Validation' : avg_vloss },\n",
    "                        epoch_number)\n",
    "        writer.add_scalars('Validation MAE',\n",
    "                        { 'Validation' : avg_vmae },\n",
    "                        epoch_number)\n",
    "        writer.add_scalars('Validation R2',\n",
    "                        { 'Validation' : avg_vr2 },\n",
    "                        epoch_number)\n",
    "\n",
    "        model_path = 'model_{}_{}_{}_{}'.format(BACKBONE_TYPE, HEAD_TYPE, timestamp, epoch_number)\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = 'model_{}_{}_{}_{}_best'.format(BACKBONE_TYPE, HEAD_TYPE, timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        if not os.path.exists(f\"HF-{model_path}\"):\n",
    "            os.mkdir(f\"HF-{model_path}\")\n",
    "        model.save_pretrained(f\"HF-{model_path}\")\n",
    "    \n",
    "    writer.flush()\n",
    "    \n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
